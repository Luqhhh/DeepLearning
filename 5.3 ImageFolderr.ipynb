{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a7eba19d",
   "metadata": {},
   "source": [
    "_Pre:\n",
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "trans=transforms.Compose([transforms.Resize((64,128))])\n",
    "train_data=dests.ImageFolder(root='custom_data/origin_data',transform=trans)\n",
    "for num,value in enumerate(train_data):\n",
    "    data,label=value\n",
    "    if(label==0):\n",
    "       data.save('custom_data/train_data/gray/%d_%d.jpeg'%(num,label))\n",
    "    else:\n",
    "       data.save('custom_data/train_data/red/%d_%d.jpeg'%(num,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cad1a575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08231b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"./model_parameters\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f61e119",
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda'if torch.cuda.is_available()else'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dce07127",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "if device=='cuda':\n",
    "    torch.cuda.manual_seed_all(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41d6a67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans=transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0594f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=dsets.ImageFolder(root='./custom_data/train_data',transform=trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e90edaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader=torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                        shuffle=True,\n",
    "                                        drop_last=True,\n",
    "                                        batch_size=8,\n",
    "                                        num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f3d3da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #(8,3,64,128)\n",
    "        self.layer1=torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(3,6,5),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d(2))\n",
    "        #(8,6,30,62)\n",
    "        self.layer2=torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(6,16,5),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d(2))\n",
    "        #(8,16,13,29)\n",
    "        self.fc1=torch.nn.Linear(16*13*29,120)\n",
    "        self.fc2=torch.nn.Linear(120,2)\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        self.relu=torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out1=self.layer1(x)\n",
    "        out2=self.layer2(out1)\n",
    "        out3=self.fc1(out2.view(-1,16*13*29))\n",
    "        out4=self.relu(out3)\n",
    "        out5=self.fc2(out4)\n",
    "        return out5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da0928b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "model=CNN().to(device)\n",
    "\n",
    "test_sample=torch.Tensor(3,3,64,128).to(device)\n",
    "test_out=model(test_sample)\n",
    "print(test_out.shape)\n",
    "\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "criterion=torch.nn.CrossEntropyLoss().to(device)\n",
    "total_batch=len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6757c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1],[Cost:0.322520494]\n",
      "[Epoch: 2],[Cost:0.030967999]\n",
      "[Epoch: 3],[Cost:0.008000401]\n",
      "[Epoch: 4],[Cost:0.003821855]\n",
      "[Epoch: 5],[Cost:0.002309267]\n",
      "[Epoch: 6],[Cost:0.001165453]\n",
      "[Epoch: 7],[Cost:0.000847009]\n",
      "[Epoch: 8],[Cost:0.000511847]\n",
      "[Epoch: 9],[Cost:0.000360981]\n",
      "[Epoch:10],[Cost:0.000284599]\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    avg_cost=0\n",
    "    for X,Y in data_loader:\n",
    "        X=X.to(device)\n",
    "        Y=Y.to(device)\n",
    "        hypothesis=model(X)\n",
    "        loss=criterion(hypothesis,Y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_cost+=loss/total_batch\n",
    "    print(\"[Epoch:{:2d}],[Cost:{:.9f}]\".format((epoch+1),avg_cost))\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "676c567a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.Resize((64,128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "test_data = dsets.ImageFolder(root='./custom_data/test_data', transform=trans)\n",
    "test_set = torch.utils.data.DataLoader(dataset=test_data, batch_size=len(test_data))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for num, data in enumerate(test_set):\n",
    "        imgs, label = data\n",
    "        imgs = imgs.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        prediction = model(imgs)\n",
    "        \n",
    "        correct_prediction = torch.argmax(prediction, 1) == label\n",
    "        accuracy = correct_prediction.float().mean()\n",
    "        print('Accuracy:', accuracy.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa17d75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oi",
   "language": "python",
   "name": "oi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
